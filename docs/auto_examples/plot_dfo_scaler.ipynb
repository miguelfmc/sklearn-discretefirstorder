{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Scaling input data for the DFO Regressor\n\nDFORegressor() can normalize the data internally or it can be used\nin conjunction with a sklearn scaler e.g. StandardScaler.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nfrom discretefirstorder import DFORegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a synthetic dataset with some uninformative features\nWe create a synthetic dataset with only 10 informative features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "means = np.random.randint(-10, 10, size=30)\nstds = np.random.randint(1, 5, size=30)\ncov = np.diag(stds**2)\nepsilon = 5\n\nnp.random.seed(42)\n\nX = np.random.multivariate_normal(means, cov, size=10000)\ncoef = np.concatenate(\n    (np.array([10, -9, 8, -7, 6, -5, 4, -3, 2, -1]), np.zeros(20))\n)\ny = X @ coef + 5 * np.random.normal(size=10000)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.15, random_state=42\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit a DFORegressor directly on the data\nWe fit the DFORegressor with fit_intercept=True and normalize=True\nto take care of data scaling internally.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dfo = DFORegressor(k=10, fit_intercept=True, normalize=True)\ndfo.fit(X_train, y_train)\n\ndfo_score = dfo.score(X_test, y_test)\ndfo_coef_error = np.sqrt(np.sum((dfo.coef_ - coef) ** 2))\n\nprint(f\"DFO R\u00b2 score on test set: {dfo_score:.4f}\")\nprint(f\"DFO coef error: {dfo_coef_error:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit a DFORegressor in a Pipeline with StandardScaler\nNow we first scale the data with StandardScaler and then fit the model\nwith normalize=False.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline_intercept = Pipeline(\n    [\n        (\"scaler\", StandardScaler()),\n        (\"dfo\", DFORegressor(k=10, fit_intercept=True, normalize=False)),\n    ]\n)\npipeline_intercept.fit(X_train, y_train)\n\n# to compare with original coefficients we need to rescale the coefficients from the\n# model\nrescaled_coef = pipeline_intercept[\"dfo\"].coef_ / X_train.std(axis=0)\n\npipeline_intercept_score = pipeline_intercept.score(X_test, y_test)\npipeline_intercept_coef_error = np.sqrt(np.sum((rescaled_coef - coef) ** 2))\n\nprint(\n    f\"DFO with external X scaling R\u00b2 score on test set: {pipeline_intercept_score:.4f}\"\n)\nprint(\n    f\"DFO with external X scaling coef error: {pipeline_intercept_coef_error:.4f}\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit a DFORegressor in a Pipeline with StandardScaler and no intercept\nIf we don't want to fit an intercept term, we can use the same pipeline,\nsetting fit_intercept=False and fitting the model on centered target data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline_no_intercept = Pipeline(\n    [\n        (\"scaler\", StandardScaler()),\n        (\"dfo\", DFORegressor(k=10, fit_intercept=False, normalize=False)),\n    ]\n)\npipeline_no_intercept.fit(X_train, (y_train - y_train.mean()))\n\n# to compare with original coefficients we need to rescale the coefficients from the\n# model\nrescaled_coef = pipeline_no_intercept[\"dfo\"].coef_ / X_train.std(axis=0)\n\npipeline_no_intercept_score = pipeline_no_intercept.score(X_test, y_test)\npipeline_no_intercept_coef_error = np.sqrt(np.sum((rescaled_coef - coef) ** 2))\n\nprint(\n    f\"DFO with external X scaling and no intercept R\u00b2 score on test set: {pipeline_no_intercept_score:.4f}\"\n)\nprint(\n    f\"DFO with external X scaling and no intercept coef error: {pipeline_no_intercept_coef_error:.4f}\"\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}